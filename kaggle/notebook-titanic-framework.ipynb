{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-01-21T04:54:32.09867Z","iopub.status.busy":"2022-01-21T04:54:32.098251Z","iopub.status.idle":"2022-01-21T04:54:32.134698Z","shell.execute_reply":"2022-01-21T04:54:32.133787Z","shell.execute_reply.started":"2022-01-21T04:54:32.098565Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:32.136799Z","iopub.status.busy":"2022-01-21T04:54:32.13648Z","iopub.status.idle":"2022-01-21T04:54:33.689423Z","shell.execute_reply":"2022-01-21T04:54:33.688488Z","shell.execute_reply.started":"2022-01-21T04:54:32.136763Z"},"trusted":true},"outputs":[],"source":["#Common Model Algorithms\n","from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n","from xgboost import XGBClassifier\n","\n","#Common Model Helpers\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","from sklearn import feature_selection\n","from sklearn import model_selection\n","from sklearn import metrics\n","\n","#Visualization\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import matplotlib.pylab as pylab\n","import seaborn as sns\n","import pandas as pd\n","# from pandas.tools.plotting import scatter_matrix\n","\n","#Configure Visualization Defaults\n","#%matplotlib inline = show plots in Jupyter Notebook browser\n","%matplotlib inline\n","mpl.style.use('ggplot')\n","sns.set_style('white')\n","pylab.rcParams['figure.figsize'] = 12,8"]},{"cell_type":"markdown","metadata":{},"source":["Import dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:33.691246Z","iopub.status.busy":"2022-01-21T04:54:33.690895Z","iopub.status.idle":"2022-01-21T04:54:33.765514Z","shell.execute_reply":"2022-01-21T04:54:33.764585Z","shell.execute_reply.started":"2022-01-21T04:54:33.691202Z"},"trusted":true},"outputs":[],"source":["data_raw = pd.read_csv('../input/titanic/train.csv')\n","data_val  = pd.read_csv('../input/titanic/test.csv')\n","\n","data1 = data_raw.copy(deep = True)\n","\n","data_cleaner = [data1, data_val]\n","\n","print (data_raw.info())\n","\n","data_raw.sample(10)"]},{"cell_type":"markdown","metadata":{},"source":["Cleaning: correcting, completing, creating and converting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:33.767504Z","iopub.status.busy":"2022-01-21T04:54:33.767256Z","iopub.status.idle":"2022-01-21T04:54:33.818166Z","shell.execute_reply":"2022-01-21T04:54:33.817386Z","shell.execute_reply.started":"2022-01-21T04:54:33.767475Z"},"trusted":true},"outputs":[],"source":["# find missing data\n","\n","print('Train columns with null values:\\n', data1.isnull().sum())\n","print('Test/Validation columns with null values:\\n', data_val.isnull().sum())\n","\n","data_raw.describe(include = 'all')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:33.8198Z","iopub.status.busy":"2022-01-21T04:54:33.819591Z","iopub.status.idle":"2022-01-21T04:54:33.836449Z","shell.execute_reply":"2022-01-21T04:54:33.835569Z","shell.execute_reply.started":"2022-01-21T04:54:33.819774Z"},"trusted":true},"outputs":[],"source":["# fill in missing values\n","for dataset in data_cleaner:\n","    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n","    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n","    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n","    \n","# drop columns\n","drop_column = ['PassengerId','Cabin', 'Ticket']\n","data1.drop(drop_column, axis=1, inplace = True)\n","\n","print(data1.isnull().sum())\n","print(data_val.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:33.837948Z","iopub.status.busy":"2022-01-21T04:54:33.837741Z","iopub.status.idle":"2022-01-21T04:54:33.941154Z","shell.execute_reply":"2022-01-21T04:54:33.940292Z","shell.execute_reply.started":"2022-01-21T04:54:33.837922Z"},"trusted":true},"outputs":[],"source":["# feature engineering\n","for dataset in data_cleaner:    \n","\n","    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n","\n","    dataset['IsAlone'] = 1 \n","    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 \n","\n","    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n","\n","    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n","\n","    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n","\n","stat_min = 10 \n","title_names = (data1['Title'].value_counts() < stat_min) \n","\n","data1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n","print(data1['Title'].value_counts())\n","\n","\n","data1.info()\n","data_val.info()\n","data1.sample(10)"]},{"cell_type":"markdown","metadata":{},"source":["Encode categorical data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:33.94305Z","iopub.status.busy":"2022-01-21T04:54:33.942669Z","iopub.status.idle":"2022-01-21T04:54:33.999904Z","shell.execute_reply":"2022-01-21T04:54:33.99922Z","shell.execute_reply.started":"2022-01-21T04:54:33.943007Z"},"trusted":true},"outputs":[],"source":["# label encoding\n","label = LabelEncoder()\n","for dataset in data_cleaner:    \n","    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n","    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n","    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n","    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n","    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n","\n","\n","# Y \n","Target = ['Survived']\n","\n","\n","data1_x = ['Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] #pretty name/values for charts\n","data1_x_calc = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code','SibSp', 'Parch', 'Age', 'Fare'] #coded for algorithm calculation\n","data1_xy =  Target + data1_x\n","print('Original X Y: ', data1_xy, '\\n')\n","\n","\n","#define x variables for original w/bin features to remove continuous variables\n","data1_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\n","data1_xy_bin = Target + data1_x_bin\n","print('Bin X Y: ', data1_xy_bin, '\\n')\n","\n","\n","#define x and y variables for dummy features original\n","data1_dummy = pd.get_dummies(data1[data1_x])\n","data1_x_dummy = data1_dummy.columns.tolist()\n","data1_xy_dummy = Target + data1_x_dummy\n","print('Dummy X Y: ', data1_xy_dummy, '\\n')\n","\n","\n","\n","data1_dummy.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["split train and test data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:34.001623Z","iopub.status.busy":"2022-01-21T04:54:34.001173Z","iopub.status.idle":"2022-01-21T04:54:34.027432Z","shell.execute_reply":"2022-01-21T04:54:34.026729Z","shell.execute_reply.started":"2022-01-21T04:54:34.001584Z"},"trusted":true},"outputs":[],"source":["train1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\n","train1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target] , random_state = 0)\n","train1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state = 0)\n","\n","\n","print(\"Data1 Shape: {}\".format(data1.shape))\n","print(\"Train1 Shape: {}\".format(train1_x.shape))\n","print(\"Test1 Shape: {}\".format(test1_x.shape))\n","\n","train1_x_bin.head()"]},{"cell_type":"markdown","metadata":{},"source":["exploratory data analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:34.029921Z","iopub.status.busy":"2022-01-21T04:54:34.029587Z","iopub.status.idle":"2022-01-21T04:54:34.098979Z","shell.execute_reply":"2022-01-21T04:54:34.098395Z","shell.execute_reply.started":"2022-01-21T04:54:34.029892Z"},"trusted":true},"outputs":[],"source":["# Discrete Variable Correlation by Survival using\n","# group by aka pivot table\n","for x in data1_x:\n","    if data1[x].dtype != 'float64' :\n","        print('Survival Correlation by:', x)\n","        print(data1[[x, Target[0]]].groupby(x, as_index=False).mean())\n","        print('-'*10, '\\n')\n","\n","# crosstabs\n","print(pd.crosstab(data1['Title'],data1[Target[0]]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:34.100627Z","iopub.status.busy":"2022-01-21T04:54:34.099874Z","iopub.status.idle":"2022-01-21T04:54:35.691197Z","shell.execute_reply":"2022-01-21T04:54:35.690238Z","shell.execute_reply.started":"2022-01-21T04:54:34.100593Z"},"trusted":true},"outputs":[],"source":["\n","plt.figure(figsize=[16,12])\n","\n","plt.subplot(231)\n","plt.boxplot(x=data1['Fare'], showmeans = True, meanline = True)\n","plt.title('Fare Boxplot')\n","plt.ylabel('Fare ($)')\n","\n","plt.subplot(232)\n","plt.boxplot(data1['Age'], showmeans = True, meanline = True)\n","plt.title('Age Boxplot')\n","plt.ylabel('Age (Years)')\n","\n","plt.subplot(233)\n","plt.boxplot(data1['FamilySize'], showmeans = True, meanline = True)\n","plt.title('Family Size Boxplot')\n","plt.ylabel('Family Size (#)')\n","\n","plt.subplot(234)\n","plt.hist(x = [data1[data1['Survived']==1]['Fare'], data1[data1['Survived']==0]['Fare']], \n","         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\n","plt.title('Fare Histogram by Survival')\n","plt.xlabel('Fare ($)')\n","plt.ylabel('# of Passengers')\n","plt.legend()\n","\n","plt.subplot(235)\n","plt.hist(x = [data1[data1['Survived']==1]['Age'], data1[data1['Survived']==0]['Age']], \n","         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\n","plt.title('Age Histogram by Survival')\n","plt.xlabel('Age (Years)')\n","plt.ylabel('# of Passengers')\n","plt.legend()\n","\n","plt.subplot(236)\n","plt.hist(x = [data1[data1['Survived']==1]['FamilySize'], data1[data1['Survived']==0]['FamilySize']], \n","         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\n","plt.title('Family Size Histogram by Survival')\n","plt.xlabel('Family Size (#)')\n","plt.ylabel('# of Passengers')\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:35.693522Z","iopub.status.busy":"2022-01-21T04:54:35.692846Z","iopub.status.idle":"2022-01-21T04:54:37.526867Z","shell.execute_reply":"2022-01-21T04:54:37.526147Z","shell.execute_reply.started":"2022-01-21T04:54:35.693482Z"},"trusted":true},"outputs":[],"source":["# use seaborn graphics for multi-variable comparison\n","\n","#graph individual features by survival\n","fig, saxis = plt.subplots(2, 3,figsize=(16,12))\n","\n","sns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\n","sns.barplot(x = 'Pclass', y = 'Survived', order=[1,2,3], data=data1, ax = saxis[0,1])\n","sns.barplot(x = 'IsAlone', y = 'Survived', order=[1,0], data=data1, ax = saxis[0,2])\n","\n","sns.pointplot(x = 'FareBin', y = 'Survived',  data=data1, ax = saxis[1,0])\n","sns.pointplot(x = 'AgeBin', y = 'Survived',  data=data1, ax = saxis[1,1])\n","sns.pointplot(x = 'FamilySize', y = 'Survived', data=data1, ax = saxis[1,2])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:37.528357Z","iopub.status.busy":"2022-01-21T04:54:37.528003Z","iopub.status.idle":"2022-01-21T04:54:38.427197Z","shell.execute_reply":"2022-01-21T04:54:38.426585Z","shell.execute_reply.started":"2022-01-21T04:54:37.528296Z"},"trusted":true},"outputs":[],"source":["fig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(16, 8))\n","\n","sns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\n","axis1.set_title('Pclass vs Fare Survival Comparison')\n","\n","sns.violinplot(x = 'Pclass', y = 'Age', hue = 'Survived', data = data1, split = True, ax = axis2)\n","axis2.set_title('Pclass vs Age Survival Comparison')\n","\n","sns.boxplot(x = 'Pclass', y ='FamilySize', hue = 'Survived', data = data1, ax = axis3)\n","axis3.set_title('Pclass vs Family Size Survival Comparison')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:38.4286Z","iopub.status.busy":"2022-01-21T04:54:38.428275Z","iopub.status.idle":"2022-01-21T04:54:39.552323Z","shell.execute_reply":"2022-01-21T04:54:39.551514Z","shell.execute_reply.started":"2022-01-21T04:54:38.428572Z"},"trusted":true},"outputs":[],"source":["# graph distribution of qualitative data: Sex\n","fig, qaxis = plt.subplots(1,3,figsize=(16,8))\n","\n","sns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\n","axis1.set_title('Sex vs Embarked Survival Comparison')\n","\n","sns.barplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data=data1, ax  = qaxis[1])\n","axis1.set_title('Sex vs Pclass Survival Comparison')\n","\n","sns.barplot(x = 'Sex', y = 'Survived', hue = 'IsAlone', data=data1, ax  = qaxis[2])\n","axis1.set_title('Sex vs IsAlone Survival Comparison')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:39.553825Z","iopub.status.busy":"2022-01-21T04:54:39.553584Z","iopub.status.idle":"2022-01-21T04:54:40.912905Z","shell.execute_reply":"2022-01-21T04:54:40.911961Z","shell.execute_reply.started":"2022-01-21T04:54:39.553795Z"},"trusted":true},"outputs":[],"source":["# more side-by-side comparisons\n","fig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(16,8))\n","\n","#how does family size factor with sex & survival compare\n","sns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n","              palette={\"male\": \"blue\", \"female\": \"pink\"},\n","              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"], ax = maxis1)\n","\n","#how does class factor with sex & survival compare\n","sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data1,\n","              palette={\"male\": \"blue\", \"female\": \"pink\"},\n","              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"], ax = maxis2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:40.914582Z","iopub.status.busy":"2022-01-21T04:54:40.914285Z","iopub.status.idle":"2022-01-21T04:54:42.448475Z","shell.execute_reply":"2022-01-21T04:54:42.447657Z","shell.execute_reply.started":"2022-01-21T04:54:40.914548Z"},"trusted":true},"outputs":[],"source":["# how does embark port factor with class, sex, and survival compare\n","e = sns.FacetGrid(data1, col = 'Embarked')\n","e.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\n","e.add_legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:42.450497Z","iopub.status.busy":"2022-01-21T04:54:42.450181Z","iopub.status.idle":"2022-01-21T04:54:43.03Z","shell.execute_reply":"2022-01-21T04:54:43.029247Z","shell.execute_reply.started":"2022-01-21T04:54:42.450454Z"},"trusted":true},"outputs":[],"source":["# plot distributions of age of passengers who survived or did not survive\n","a = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\n","a.map(sns.kdeplot, 'Age', shade= True )\n","a.set(xlim=(0 , data1['Age'].max()))\n","a.add_legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:43.031606Z","iopub.status.busy":"2022-01-21T04:54:43.03138Z","iopub.status.idle":"2022-01-21T04:54:45.172763Z","shell.execute_reply":"2022-01-21T04:54:45.171782Z","shell.execute_reply.started":"2022-01-21T04:54:43.031578Z"},"trusted":true},"outputs":[],"source":["# histogram comparison of sex, class, and age by survival\n","h = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\n","h.map(plt.hist, 'Age', alpha = .75)\n","h.add_legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:54:45.174523Z","iopub.status.busy":"2022-01-21T04:54:45.174162Z","iopub.status.idle":"2022-01-21T04:55:26.985051Z","shell.execute_reply":"2022-01-21T04:55:26.984092Z","shell.execute_reply.started":"2022-01-21T04:54:45.174492Z"},"trusted":true},"outputs":[],"source":["#pair plots of entire dataset\n","pp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\n","pp.set(xticklabels=[])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:55:26.986633Z","iopub.status.busy":"2022-01-21T04:55:26.986395Z","iopub.status.idle":"2022-01-21T04:55:28.249134Z","shell.execute_reply":"2022-01-21T04:55:28.248291Z","shell.execute_reply.started":"2022-01-21T04:55:26.986602Z"},"trusted":true},"outputs":[],"source":["# correlation heatmap of dataset\n","def correlation_heatmap(df):\n","    _ , ax = plt.subplots(figsize =(14, 12))\n","    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n","    \n","    _ = sns.heatmap(\n","        df.corr(), \n","        cmap = colormap,\n","        square=True, \n","        cbar_kws={'shrink':.9 }, \n","        ax=ax,\n","        annot=True, \n","        linewidths=0.1,vmax=1.0, linecolor='white',\n","        annot_kws={'fontsize':12 }\n","    )\n","    \n","    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n","\n","correlation_heatmap(data1)"]},{"cell_type":"markdown","metadata":{},"source":["Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ssss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T04:58:05.273714Z","iopub.status.busy":"2022-01-21T04:58:05.273415Z","iopub.status.idle":"2022-01-21T04:58:24.14828Z","shell.execute_reply":"2022-01-21T04:58:24.147376Z","shell.execute_reply.started":"2022-01-21T04:58:05.273684Z"},"trusted":true},"outputs":[],"source":["#Machine Learning Algorithm (MLA) Selection and Initialization\n","MLA = [\n","    #Ensemble Methods\n","    ensemble.AdaBoostClassifier(),\n","    ensemble.BaggingClassifier(),\n","    ensemble.ExtraTreesClassifier(),\n","    ensemble.GradientBoostingClassifier(),\n","    ensemble.RandomForestClassifier(),\n","\n","    #Gaussian Processes\n","    gaussian_process.GaussianProcessClassifier(),\n","    \n","    #GLM\n","    linear_model.LogisticRegressionCV(),\n","    linear_model.PassiveAggressiveClassifier(),\n","    linear_model.RidgeClassifierCV(),\n","    linear_model.SGDClassifier(),\n","    linear_model.Perceptron(),\n","    \n","    #Navies Bayes\n","    naive_bayes.BernoulliNB(),\n","    naive_bayes.GaussianNB(),\n","    \n","    #Nearest Neighbor\n","    neighbors.KNeighborsClassifier(),\n","    \n","    #SVM\n","    svm.SVC(probability=True),\n","    svm.NuSVC(probability=True),\n","    svm.LinearSVC(),\n","    \n","    #Trees    \n","    tree.DecisionTreeClassifier(),\n","    tree.ExtraTreeClassifier(),\n","    \n","    #Discriminant Analysis\n","    discriminant_analysis.LinearDiscriminantAnalysis(),\n","    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n","\n","    \n","    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n","    XGBClassifier()    \n","    ]\n","\n","\n","\n","#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n","#note: this is an alternative to train_test_split\n","cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n","\n","#create table to compare MLA metrics\n","MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n","MLA_compare = pd.DataFrame(columns = MLA_columns)\n","\n","#create table to compare MLA predictions\n","MLA_predict = data1[Target]\n","\n","#index through MLA and save performance to table\n","row_index = 0\n","for alg in MLA:\n","\n","    MLA_name = alg.__class__.__name__\n","    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n","    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n","    \n","    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score = True)\n","\n","    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n","    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n","    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n","    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n","    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n","    \n","\n","    alg.fit(data1[data1_x_bin], data1[Target])\n","    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n","    \n","    row_index+=1\n","\n","    \n","MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n","MLA_compare\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:00:31.969752Z","iopub.status.busy":"2022-01-21T05:00:31.968771Z","iopub.status.idle":"2022-01-21T05:00:32.503083Z","shell.execute_reply":"2022-01-21T05:00:32.502224Z","shell.execute_reply.started":"2022-01-21T05:00:31.969707Z"},"trusted":true},"outputs":[],"source":["sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n","\n","plt.title('Machine Learning Algorithm Accuracy Score \\n')\n","plt.xlabel('Accuracy Score (%)')\n","plt.ylabel('Algorithm')"]},{"cell_type":"markdown","metadata":{},"source":["Tune model with hyperparameters - grid search and cross validation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:20:39.734143Z","iopub.status.busy":"2022-01-21T05:20:39.733133Z","iopub.status.idle":"2022-01-21T05:20:41.201156Z","shell.execute_reply":"2022-01-21T05:20:41.200293Z","shell.execute_reply.started":"2022-01-21T05:20:39.734097Z"},"trusted":true},"outputs":[],"source":["#base model\n","dtree = tree.DecisionTreeClassifier(random_state = 0)\n","base_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score = True)\n","dtree.fit(data1[data1_x_bin], data1[Target])\n","\n","print('BEFORE DT Parameters: ', dtree.get_params())\n","print(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n","print(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n","print(\"BEFORE DT Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n","print('-'*10)\n","\n","\n","param_grid = {'criterion': ['gini', 'entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n","              #'splitter': ['best', 'random'], #splitting methodology; two supported strategies - default is best\n","              'max_depth': [2,4,6,8,10,None], #max depth tree can grow; default is none\n","              #'min_samples_split': [2,5,10,.03,.05], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n","              #'min_samples_leaf': [1,5,10,.03,.05], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n","              #'max_features': [None, 'auto'], #max features to consider when performing split; default none or all\n","              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n","             }\n","\n","tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split, return_train_score = True)\n","tune_model.fit(data1[data1_x_bin], data1[Target])\n","\n","#print(tune_model.cv_results_.keys())\n","#print(tune_model.cv_results_['params'])\n","print('AFTER DT Parameters: ', tune_model.best_params_)\n","#print(tune_model.cv_results_['mean_train_score'])\n","print(\"AFTER DT Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n","#print(tune_model.cv_results_['mean_test_score'])\n","print(\"AFTER DT Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n","print(\"AFTER DT Test w/bin score 3*std: +/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n","print('-'*10)\n"]},{"cell_type":"markdown","metadata":{},"source":["Tune model with feature selection - recursive feature elimination with cross validation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:27:56.710551Z","iopub.status.busy":"2022-01-21T05:27:56.710187Z","iopub.status.idle":"2022-01-21T05:27:58.293756Z","shell.execute_reply":"2022-01-21T05:27:58.29291Z","shell.execute_reply.started":"2022-01-21T05:27:56.710515Z"},"trusted":true},"outputs":[],"source":["#base model\n","print('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \n","print('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n","\n","print(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n","print(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n","print(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n","\n","#feature selection\n","dtree_rfe = feature_selection.RFECV(dtree, step = 1, scoring = 'accuracy', cv = cv_split)\n","dtree_rfe.fit(data1[data1_x_bin], data1[Target])\n","\n","#transform x&y to reduced features and fit new model\n","#alternative: can use pipeline to reduce fit and transform steps: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n","X_rfe = data1[data1_x_bin].columns.values[dtree_rfe.get_support()]\n","rfe_results = model_selection.cross_validate(dtree, data1[X_rfe], data1[Target], cv  = cv_split, return_train_score = True)\n","\n","#print(dtree_rfe.grid_scores_)\n","print('AFTER DT RFE Training Shape New: ', data1[X_rfe].shape) \n","print('AFTER DT RFE Training Columns New: ', X_rfe)\n","\n","print(\"AFTER DT RFE Training w/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \n","print(\"AFTER DT RFE Test w/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\n","print(\"AFTER DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\n","print('-'*10)\n","\n","#tune rfe model\n","rfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split, return_train_score = True)\n","rfe_tune_model.fit(data1[X_rfe], data1[Target])\n","\n","#print(rfe_tune_model.cv_results_.keys())\n","#print(rfe_tune_model.cv_results_['params'])\n","print('AFTER DT RFE Tuned Parameters: ', rfe_tune_model.best_params_)\n","#print(rfe_tune_model.cv_results_['mean_train_score'])\n","print(\"AFTER DT RFE Tuned Training w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n","#print(rfe_tune_model.cv_results_['mean_test_score'])\n","print(\"AFTER DT RFE Tuned Test w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n","print(\"AFTER DT RFE Tuned Test w/bin score 3*std: +/- {:.2f}\". format(rfe_tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:29:47.578042Z","iopub.status.busy":"2022-01-21T05:29:47.577763Z","iopub.status.idle":"2022-01-21T05:29:47.582421Z","shell.execute_reply":"2022-01-21T05:29:47.581499Z","shell.execute_reply.started":"2022-01-21T05:29:47.578013Z"},"trusted":true},"outputs":[],"source":["# Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n","\n","# import graphviz \n","# dot_data = tree.export_graphviz(dtree, out_file=None, \n","#                                 feature_names = data1_x_bin, class_names = True,\n","#                                 filled = True, rounded = True)\n","# graph = graphviz.Source(dot_data) \n","# graph"]},{"cell_type":"markdown","metadata":{},"source":["validate and implement"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:30:10.930181Z","iopub.status.busy":"2022-01-21T05:30:10.92979Z","iopub.status.idle":"2022-01-21T05:30:14.037127Z","shell.execute_reply":"2022-01-21T05:30:14.036228Z","shell.execute_reply.started":"2022-01-21T05:30:10.930137Z"},"trusted":true},"outputs":[],"source":["correlation_heatmap(MLA_predict)"]},{"cell_type":"markdown","metadata":{},"source":["voting classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:33:32.219972Z","iopub.status.busy":"2022-01-21T05:33:32.219237Z","iopub.status.idle":"2022-01-21T05:34:07.514865Z","shell.execute_reply":"2022-01-21T05:34:07.5136Z","shell.execute_reply.started":"2022-01-21T05:33:32.219921Z"},"trusted":true},"outputs":[],"source":["#why choose one model, when you can pick them all with voting classifier\n","#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n","#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\n","vote_est = [\n","    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n","    ('ada', ensemble.AdaBoostClassifier()),\n","    ('bc', ensemble.BaggingClassifier()),\n","    ('etc',ensemble.ExtraTreesClassifier()),\n","    ('gbc', ensemble.GradientBoostingClassifier()),\n","    ('rfc', ensemble.RandomForestClassifier()),\n","\n","    #Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc\n","    ('gpc', gaussian_process.GaussianProcessClassifier()),\n","    \n","    #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","    ('lr', linear_model.LogisticRegressionCV()),\n","    \n","    #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n","    ('bnb', naive_bayes.BernoulliNB()),\n","    ('gnb', naive_bayes.GaussianNB()),\n","    \n","    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n","    ('knn', neighbors.KNeighborsClassifier()),\n","    \n","    #SVM: http://scikit-learn.org/stable/modules/svm.html\n","    ('svc', svm.SVC(probability=True)),\n","    \n","    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n","   ('xgb', XGBClassifier())\n","\n","]\n","\n","\n","#Hard Vote or majority rules\n","vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n","vote_hard_cv = model_selection.cross_validate(vote_hard, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score = True)\n","vote_hard.fit(data1[data1_x_bin], data1[Target])\n","\n","print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n","print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n","print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n","print('-'*10)\n","\n","#Soft Vote or weighted probabilities\n","vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n","vote_soft_cv = model_selection.cross_validate(vote_soft, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score = True)\n","vote_soft.fit(data1[data1_x_bin], data1[Target])\n","\n","print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n","print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n","print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n","print('-'*10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:36:11.583701Z","iopub.status.busy":"2022-01-21T05:36:11.583401Z","iopub.status.idle":"2022-01-21T05:36:11.601444Z","shell.execute_reply":"2022-01-21T05:36:11.600656Z","shell.execute_reply.started":"2022-01-21T05:36:11.583665Z"},"trusted":true},"outputs":[],"source":["#IMPORTANT: THIS SECTION IS UNDER CONSTRUCTION!!!! 12.24.17\n","#UPDATE: This section was scrapped for the next section; as it's more computational friendly.\n","\n","#WARNING: Running is very computational intensive and time expensive\n","#code is written for experimental/developmental purposes and not production ready\n","\n","\n","#tune each estimator before creating a super model\n","#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n","grid_n_estimator = [50,100,300]\n","grid_ratio = [.1,.25,.5,.75,1.0]\n","grid_learn = [.01,.03,.05,.1,.25]\n","grid_max_depth = [2,4,6,None]\n","grid_min_samples = [5,10,.03,.05,.10]\n","grid_criterion = ['gini', 'entropy']\n","grid_bool = [True, False]\n","grid_seed = [0]\n","\n","vote_param = [{\n","#            #http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n","            'ada__n_estimators': grid_n_estimator,\n","            'ada__learning_rate': grid_ratio,\n","            'ada__algorithm': ['SAMME', 'SAMME.R'],\n","            'ada__random_state': grid_seed,\n","    \n","            #http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n","            'bc__n_estimators': grid_n_estimator,\n","            'bc__max_samples': grid_ratio,\n","            'bc__oob_score': grid_bool, \n","            'bc__random_state': grid_seed,\n","            \n","            #http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n","            'etc__n_estimators': grid_n_estimator,\n","            'etc__criterion': grid_criterion,\n","            'etc__max_depth': grid_max_depth,\n","            'etc__random_state': grid_seed,\n","\n","\n","            #http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n","            'gbc__loss': ['deviance', 'exponential'],\n","            'gbc__learning_rate': grid_ratio,\n","            'gbc__n_estimators': grid_n_estimator,\n","            'gbc__criterion': ['friedman_mse', 'mse', 'mae'],\n","            'gbc__max_depth': grid_max_depth,\n","            'gbc__min_samples_split': grid_min_samples,\n","            'gbc__min_samples_leaf': grid_min_samples,      \n","            'gbc__random_state': grid_seed,\n","    \n","            #http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n","            'rfc__n_estimators': grid_n_estimator,\n","            'rfc__criterion': grid_criterion,\n","            'rfc__max_depth': grid_max_depth,\n","            'rfc__min_samples_split': grid_min_samples,\n","            'rfc__min_samples_leaf': grid_min_samples,   \n","            'rfc__bootstrap': grid_bool,\n","            'rfc__oob_score': grid_bool, \n","            'rfc__random_state': grid_seed,\n","        \n","            #http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n","            'lr__fit_intercept': grid_bool,\n","            'lr__penalty': ['l1','l2'],\n","            'lr__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n","            'lr__random_state': grid_seed,\n","            \n","            #http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n","            'bnb__alpha': grid_ratio,\n","            'bnb__prior': grid_bool,\n","            'bnb__random_state': grid_seed,\n","    \n","            #http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n","            'knn__n_neighbors': [1,2,3,4,5,6,7],\n","            'knn__weights': ['uniform', 'distance'],\n","            'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n","            'knn__random_state': grid_seed,\n","            \n","            #http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n","            #http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r\n","            'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","            'svc__C': grid_max_depth,\n","            'svc__gamma': grid_ratio,\n","            'svc__decision_function_shape': ['ovo', 'ovr'],\n","            'svc__probability': [True],\n","            'svc__random_state': grid_seed,\n","    \n","    \n","            #http://xgboost.readthedocs.io/en/latest/parameter.html\n","            'xgb__learning_rate': grid_ratio,\n","            'xgb__max_depth': [2,4,6,8,10],\n","            'xgb__tree_method': ['exact', 'approx', 'hist'],\n","            'xgb__objective': ['reg:linear', 'reg:logistic', 'binary:logistic'],\n","            'xgb__seed': grid_seed    \n","\n","        }]\n","\n","\n","\n","\n","#Soft Vote with tuned models\n","#grid_soft = model_selection.GridSearchCV(estimator = vote_soft, param_grid = vote_param, cv = 2, scoring = 'roc_auc')\n","#grid_soft.fit(data1[data1_x_bin], data1[Target])\n","\n","#print(grid_soft.cv_results_.keys())\n","#print(grid_soft.cv_results_['params'])\n","#print('Soft Vote Tuned Parameters: ', grid_soft.best_params_)\n","#print(grid_soft.cv_results_['mean_train_score'])\n","#print(\"Soft Vote Tuned Training w/bin set score mean: {:.2f}\". format(grid_soft.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n","#print(grid_soft.cv_results_['mean_test_score'])\n","#print(\"Soft Vote Tuned Test w/bin set score mean: {:.2f}\". format(grid_soft.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n","#print(\"Soft Vote Tuned Test w/bin score 3*std: +/- {:.2f}\". format(grid_soft.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n","#print('-'*10)\n","\n","\n","#credit: https://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/\n","#cv_keys = ('mean_test_score', 'std_test_score', 'params')\n","#for r, _ in enumerate(grid_soft.cv_results_['mean_test_score']):\n","#    print(\"%0.3f +/- %0.2f %r\"\n","#          % (grid_soft.cv_results_[cv_keys[0]][r],\n","#             grid_soft.cv_results_[cv_keys[1]][r] / 2.0,\n","#             grid_soft.cv_results_[cv_keys[2]][r]))\n","\n","\n","#print('-'*10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-21T05:38:38.333604Z","iopub.status.busy":"2022-01-21T05:38:38.333267Z","iopub.status.idle":"2022-01-21T05:53:29.190635Z","shell.execute_reply":"2022-01-21T05:53:29.189981Z","shell.execute_reply.started":"2022-01-21T05:38:38.333566Z"},"trusted":true},"outputs":[],"source":["#WARNING: Running is very computational intensive and time expensive.\n","#Code is written for experimental/developmental purposes and not production ready!\n","\n","\n","#Hyperparameter Tune with GridSearchCV: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n","grid_n_estimator = [10, 50, 100, 300]\n","grid_ratio = [.1, .25, .5, .75, 1.0]\n","grid_learn = [.01, .03, .05, .1, .25]\n","grid_max_depth = [2, 4, 6, 8, 10, None]\n","grid_min_samples = [5, 10, .03, .05, .10]\n","grid_criterion = ['gini', 'entropy']\n","grid_bool = [True, False]\n","grid_seed = [0]\n","\n","\n","grid_param = [\n","            [{\n","            #AdaBoostClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n","            'n_estimators': grid_n_estimator, #default=50\n","            'learning_rate': grid_learn, #default=1\n","            #'algorithm': ['SAMME', 'SAMME.R'], #default=’SAMME.R\n","            'random_state': grid_seed\n","            }],\n","       \n","    \n","            [{\n","            #BaggingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n","            'n_estimators': grid_n_estimator, #default=10\n","            'max_samples': grid_ratio, #default=1.0\n","            'random_state': grid_seed\n","             }],\n","\n","    \n","            [{\n","            #ExtraTreesClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n","            'n_estimators': grid_n_estimator, #default=10\n","            'criterion': grid_criterion, #default=”gini”\n","            'max_depth': grid_max_depth, #default=None\n","            'random_state': grid_seed\n","             }],\n","\n","\n","            [{\n","            #GradientBoostingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n","            #'loss': ['deviance', 'exponential'], #default=’deviance’\n","            'learning_rate': [.05], #default=0.1 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n","            'n_estimators': [300], #default=100 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n","            #'criterion': ['friedman_mse', 'mse', 'mae'], #default=”friedman_mse”\n","            'max_depth': grid_max_depth, #default=3   \n","            'random_state': grid_seed\n","             }],\n","\n","    \n","            [{\n","            #RandomForestClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n","            'n_estimators': grid_n_estimator, #default=10\n","            'criterion': grid_criterion, #default=”gini”\n","            'max_depth': grid_max_depth, #default=None\n","            'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n","            'random_state': grid_seed\n","             }],\n","    \n","            [{    \n","            #GaussianProcessClassifier\n","            'max_iter_predict': grid_n_estimator, #default: 100\n","            'random_state': grid_seed\n","            }],\n","        \n","    \n","            [{\n","            #LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n","            'fit_intercept': grid_bool, #default: True\n","            #'penalty': ['l1','l2'],\n","            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs\n","            'random_state': grid_seed\n","             }],\n","            \n","    \n","            [{\n","            #BernoulliNB - http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n","            'alpha': grid_ratio, #default: 1.0\n","             }],\n","    \n","    \n","            #GaussianNB - \n","            [{}],\n","    \n","            [{\n","            #KNeighborsClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n","            'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n","            'weights': ['uniform', 'distance'], #default = ‘uniform’\n","            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n","            }],\n","            \n","    \n","            [{\n","            #SVC - http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n","            #http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r\n","            #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","            'C': [1,2,3,4,5], #default=1.0\n","            'gamma': grid_ratio, #edfault: auto\n","            'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n","            'probability': [True],\n","            'random_state': grid_seed\n","             }],\n","\n","    \n","            [{\n","            #XGBClassifier - http://xgboost.readthedocs.io/en/latest/parameter.html\n","            'learning_rate': grid_learn, #default: .3\n","            'max_depth': [1,2,4,6,8,10], #default 2\n","            'n_estimators': grid_n_estimator, \n","            'seed': grid_seed  \n","             }]   \n","        ]\n","\n","\n","import time\n","start_total = time.perf_counter() #https://docs.python.org/3/library/time.html#time.perf_counter\n","for clf, param in zip (vote_est, grid_param): \n","\n","    #print(clf[1]) #vote_est is a list of tuples, index 0 is the name and index 1 is the algorithm\n","    #print(param)\n","    \n","    \n","    start = time.perf_counter()        \n","    best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = cv_split, scoring = 'roc_auc', return_train_score = True)\n","    best_search.fit(data1[data1_x_bin], data1[Target])\n","    run = time.perf_counter() - start\n","\n","    best_param = best_search.best_params_\n","    print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n","    clf[1].set_params(**best_param) \n","\n","\n","run_total = time.perf_counter() - start_total\n","print('Total optimization time was {:.2f} minutes.'.format(run_total/60))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Hard Vote or majority rules w/Tuned Hyperparameters\n","grid_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n","grid_hard_cv = model_selection.cross_validate(grid_hard, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score = True)\n","grid_hard.fit(data1[data1_x_bin], data1[Target])\n","\n","print(\"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_hard_cv['train_score'].mean()*100)) \n","print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\n","print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\n","print('-'*10)\n","\n","#Soft Vote or weighted probabilities w/Tuned Hyperparameters\n","grid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n","grid_soft_cv = model_selection.cross_validate(grid_soft, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score = True)\n","grid_soft.fit(data1[data1_x_bin], data1[Target])\n","\n","print(\"Soft Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_soft_cv['train_score'].mean()*100)) \n","print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\n","print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\n","print('-'*10)\n","\n","\n","#12/31/17 tuned with data1_x_bin\n","#The best parameter for AdaBoostClassifier is {'learning_rate': 0.1, 'n_estimators': 300, 'random_state': 0} with a runtime of 33.39 seconds.\n","#The best parameter for BaggingClassifier is {'max_samples': 0.25, 'n_estimators': 300, 'random_state': 0} with a runtime of 30.28 seconds.\n","#The best parameter for ExtraTreesClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0} with a runtime of 64.76 seconds.\n","#The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 34.35 seconds.\n","#The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 76.32 seconds.\n","#The best parameter for GaussianProcessClassifier is {'max_iter_predict': 10, 'random_state': 0} with a runtime of 6.01 seconds.\n","#The best parameter for LogisticRegressionCV is {'fit_intercept': True, 'random_state': 0, 'solver': 'liblinear'} with a runtime of 8.04 seconds.\n","#The best parameter for BernoulliNB is {'alpha': 0.1} with a runtime of 0.19 seconds.\n","#The best parameter for GaussianNB is {} with a runtime of 0.04 seconds.\n","#The best parameter for KNeighborsClassifier is {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'} with a runtime of 4.84 seconds.\n","#The best parameter for SVC is {'C': 2, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'probability': True, 'random_state': 0} with a runtime of 29.39 seconds.\n","#The best parameter for XGBClassifier is {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0} with a runtime of 46.23 seconds.\n","#Total optimization time was 5.56 minutes."]},{"cell_type":"markdown","metadata":{},"source":["submission\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#prepare data for modeling\n","print(data_val.info())\n","print(\"-\"*10)\n","\n","#handmade decision tree - submission score = 0.77990\n","data_val['Survived'] = mytree(data_val).astype(int)\n","\n","\n","#decision tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990\n","#submit_dt = tree.DecisionTreeClassifier()\n","#submit_dt = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split)\n","#submit_dt.fit(data1[data1_x_bin], data1[Target])\n","#print('Best Parameters: ', submit_dt.best_params_) #Best Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n","#data_val['Survived'] = submit_dt.predict(data_val[data1_x_bin])\n","\n","\n","#bagging w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77990\n","#submit_bc = ensemble.BaggingClassifier()\n","#submit_bc = model_selection.GridSearchCV(ensemble.BaggingClassifier(), param_grid= {'n_estimators':grid_n_estimator, 'max_samples': grid_ratio, 'oob_score': grid_bool, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n","#submit_bc.fit(data1[data1_x_bin], data1[Target])\n","#print('Best Parameters: ', submit_bc.best_params_) #Best Parameters:  {'max_samples': 0.25, 'n_estimators': 500, 'oob_score': True, 'random_state': 0}\n","#data_val['Survived'] = submit_bc.predict(data_val[data1_x_bin])\n","\n","\n","#extra tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990\n","#submit_etc = ensemble.ExtraTreesClassifier()\n","#submit_etc = model_selection.GridSearchCV(ensemble.ExtraTreesClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n","#submit_etc.fit(data1[data1_x_bin], data1[Target])\n","#print('Best Parameters: ', submit_etc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}\n","#data_val['Survived'] = submit_etc.predict(data_val[data1_x_bin])\n","\n","\n","#random foreset w/full dataset modeling submission score: defaults= 0.71291, tuned= 0.73205\n","#submit_rfc = ensemble.RandomForestClassifier()\n","#submit_rfc = model_selection.GridSearchCV(ensemble.RandomForestClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n","#submit_rfc.fit(data1[data1_x_bin], data1[Target])\n","#print('Best Parameters: ', submit_rfc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}\n","#data_val['Survived'] = submit_rfc.predict(data_val[data1_x_bin])\n","\n","\n","\n","#ada boosting w/full dataset modeling submission score: defaults= 0.74162, tuned= 0.75119\n","#submit_abc = ensemble.AdaBoostClassifier()\n","#submit_abc = model_selection.GridSearchCV(ensemble.AdaBoostClassifier(), param_grid={'n_estimators': grid_n_estimator, 'learning_rate': grid_ratio, 'algorithm': ['SAMME', 'SAMME.R'], 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n","#submit_abc.fit(data1[data1_x_bin], data1[Target])\n","#print('Best Parameters: ', submit_abc.best_params_) #Best Parameters:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 300, 'random_state': 0}\n","#data_val['Survived'] = submit_abc.predict(data_val[data1_x_bin])\n","\n","\n","#gradient boosting w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77033\n","#submit_gbc = ensemble.GradientBoostingClassifier()\n","#submit_gbc = model_selection.GridSearchCV(ensemble.GradientBoostingClassifier(), param_grid={'learning_rate': grid_ratio, 'n_estimators': grid_n_estimator, 'max_depth': grid_max_depth, 'random_state':grid_seed}, scoring = 'roc_auc', cv = cv_split)\n","#submit_gbc.fit(data1[data1_x_bin], data1[Target])\n","#print('Best Parameters: ', submit_gbc.best_params_) #Best Parameters:  {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 50, 'random_state': 0}\n","#data_val['Survived'] = submit_gbc.predict(data_val[data1_x_bin])\n","\n","#extreme boosting w/full dataset modeling submission score: defaults= 0.73684, tuned= 0.77990\n","#submit_xgb = XGBClassifier()\n","#submit_xgb = model_selection.GridSearchCV(XGBClassifier(), param_grid= {'learning_rate': grid_learn, 'max_depth': [0,2,4,6,8,10], 'n_estimators': grid_n_estimator, 'seed': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n","#submit_xgb.fit(data1[data1_x_bin], data1[Target])\n","#print('Best Parameters: ', submit_xgb.best_params_) #Best Parameters:  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0}\n","#data_val['Survived'] = submit_xgb.predict(data_val[data1_x_bin])\n","\n","\n","#hard voting classifier w/full dataset modeling submission score: defaults= 0.75598, tuned = 0.77990\n","#data_val['Survived'] = vote_hard.predict(data_val[data1_x_bin])\n","data_val['Survived'] = grid_hard.predict(data_val[data1_x_bin])\n","\n","\n","#soft voting classifier w/full dataset modeling submission score: defaults= 0.73684, tuned = 0.74162\n","#data_val['Survived'] = vote_soft.predict(data_val[data1_x_bin])\n","#data_val['Survived'] = grid_soft.predict(data_val[data1_x_bin])\n","\n","\n","#submit file\n","submit = data_val[['PassengerId','Survived']]\n","submit.to_csv(\"../working/submit.csv\", index=False)\n","\n","print('Validation Data Distribution: \\n', data_val['Survived'].value_counts(normalize = True))\n","submit.sample(10)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["optimizate and strategize"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
